{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alarcon7a/paligemma-tutorial/blob/main/PaliGemma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPjl_gSYw10e"
      },
      "source": [
        "### Cargar librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12DEAtxi7Ngn"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U accelerate bitsandbytes git+https://github.com/huggingface/transformers.git gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyy9dm7Gw5ek"
      },
      "source": [
        "### HuggingFace Login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5APlkLuV8FpW"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixvzquIcw92H"
      },
      "source": [
        "## Cargando modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cemVg1B7Xp-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_id = \"google/paligemma-3b-mix-224\"\n",
        "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
        "processor = PaliGemmaProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCzb3biCgWBb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "input_image = Image.open('/content/animals.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ra4ZvwkxgXpJ"
      },
      "outputs": [],
      "source": [
        "input_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8WHK55OgmZ0"
      },
      "source": [
        "## Describir imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjMtOeDX8vcZ"
      },
      "outputs": [],
      "source": [
        "input_text = \"caption\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SBBqDxZ_G3d"
      },
      "outputs": [],
      "source": [
        "input_text = \"caption es\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PROm8RuSgtJE"
      },
      "source": [
        "## Q&A en imagenes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6gcihMvfW1L"
      },
      "outputs": [],
      "source": [
        "input_text = \"cuantos gatos hay?\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UffM37UfZGM"
      },
      "outputs": [],
      "source": [
        "input_text = \"de que raza son los perros?\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w26axoftgbhb"
      },
      "outputs": [],
      "source": [
        "input_text = \"de que raza es el gato?\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTbCvF0Agw3G"
      },
      "source": [
        "## Deteccion de objetos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aarVW_6tgzj0"
      },
      "outputs": [],
      "source": [
        "input_text = \"detect golden retriever\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYAxWgNg_d_4"
      },
      "source": [
        "### Limpiando las coordenadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja5r53OkhshJ"
      },
      "outputs": [],
      "source": [
        "output = result[len(input_text):].lstrip(\"\\n\")\n",
        "output_list = output.split(';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFHahMBdilRS"
      },
      "outputs": [],
      "source": [
        "output_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU4cfHbyAYzC"
      },
      "source": [
        "### Generar coordenadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hBtSYJmhQHE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "image_width, image_height = input_image.size\n",
        "\n",
        "_SEGMENT_DETECT_RE = re.compile(\n",
        "    r'(.*?)' +\n",
        "    r'<loc(\\d{4})>' * 4 + r'\\s*' +\n",
        "    '(?:%s)?' % (r'<seg(\\d{3})>' * 16) +\n",
        "    r'\\s*([^;<>]+)? ?(?:; )?',\n",
        ")\n",
        "\n",
        "labels, boxes = [], []\n",
        "\n",
        "for _ in output_list:\n",
        "    m = _SEGMENT_DETECT_RE.match(_)\n",
        "    gs = list(m.groups())\n",
        "    before = gs.pop(0)\n",
        "    name = gs.pop()\n",
        "    y1, x1, y2, x2 = [int(x) / 1024 for x in gs[:4]]\n",
        "    y1 = y1  * image_height\n",
        "    x1 = x1  * image_width\n",
        "    y2 = y2  * image_height\n",
        "    x2 = x2  * image_width\n",
        "    boxes.append((x1, y1, x2, y2))\n",
        "    labels.append(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTicyij620NX"
      },
      "outputs": [],
      "source": [
        "boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xgwVJoF21Kl"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XERhigfAbiA"
      },
      "source": [
        "### Generando imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acfSO49EhDQY"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "image_copy = input_image.copy()\n",
        "\n",
        "draw = ImageDraw.Draw(image_copy)\n",
        "for i in range(len(boxes)):\n",
        "  draw.rectangle(boxes[i], outline=\"red\", width=8)\n",
        "  plt.text(boxes[i][0], boxes[i][1], labels[i], color='red', fontsize=12)\n",
        "# Mostrar la imagen con el rectángulo\n",
        "plt.imshow(image_copy)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkTkt6bTAUEr"
      },
      "source": [
        "### Un ejemplo mas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaLSvoq38KWw"
      },
      "outputs": [],
      "source": [
        "input_image = Image.open('/content/bodegon.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BVgzxxiy8NIJ"
      },
      "outputs": [],
      "source": [
        "input_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvRUmfMr8i9q"
      },
      "outputs": [],
      "source": [
        "input_text = \"detect bottle ; apple; lemon\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nexkXGwj8n4S"
      },
      "outputs": [],
      "source": [
        "output = result[len(input_text):].lstrip(\"\\n\")\n",
        "output_list = output.split(';')\n",
        "output_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMIgmbnP8SZF"
      },
      "outputs": [],
      "source": [
        "def get_coordinates(output_list, image_height,image_width ):\n",
        "  labels, boxes = [], []\n",
        "\n",
        "  for _ in output_list:\n",
        "      m = _SEGMENT_DETECT_RE.match(_)\n",
        "      gs = list(m.groups())\n",
        "      before = gs.pop(0)\n",
        "      name = gs.pop()\n",
        "      y1, x1, y2, x2 = [int(x) / 1024 for x in gs[:4]]\n",
        "      y1 = y1  * image_height\n",
        "      x1 = x1  * image_width\n",
        "      y2 = y2  * image_height\n",
        "      x2 = x2  * image_width\n",
        "      boxes.append((x1, y1, x2, y2))\n",
        "      labels.append(name)\n",
        "  return boxes, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0nZLgQH9fNK"
      },
      "outputs": [],
      "source": [
        "image_width, image_height = input_image.size\n",
        "boxes, labels = get_coordinates(output_list, image_height,image_width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE6Zf1fD9r7B"
      },
      "outputs": [],
      "source": [
        "def draw_detection(image, boxes, labels):\n",
        "  draw = ImageDraw.Draw(image_copy)\n",
        "  for i in range(len(boxes)):\n",
        "    draw.rectangle(boxes[i], outline=\"red\", width=8)\n",
        "    plt.text(boxes[i][0], boxes[i][1], labels[i], color='red', fontsize=12)\n",
        "  # Mostrar la imagen con el rectángulo\n",
        "  plt.imshow(image_copy)\n",
        "  plt.axis('off')\n",
        "  plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlasP4IDAGeE"
      },
      "outputs": [],
      "source": [
        "image_copy = input_image.copy()\n",
        "draw_detection(image_copy,boxes,labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZu6PRrLBXbk"
      },
      "source": [
        "## Segmentacion de objetos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD19b_DaBWp0"
      },
      "outputs": [],
      "source": [
        "input_text = \"segment bottle ; lemon\"\n",
        "inputs = processor(text=input_text, images=input_image,\n",
        "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "model.to(device)\n",
        "inputs = inputs.to(dtype=model.dtype)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model.generate(**inputs, max_length=496)\n",
        "\n",
        "result = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTKCz_1JBks3"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "hf_hub_download(repo_id=\"google/paligemma-hf\", filename=\"vae-oid.npz\",\n",
        "                repo_type=\"space\", local_dir=\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIRLny2UBnk3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import functools\n",
        "import PIL\n",
        "\n",
        "_MODEL_PATH = 'vae-oid.npz'\n",
        "\n",
        "_SEGMENT_DETECT_RE = re.compile(\n",
        "    r'(.*?)' +\n",
        "    r'<loc(\\d{4})>' * 4 + r'\\s*' +\n",
        "    '(?:%s)?' % (r'<seg(\\d{3})>' * 16) +\n",
        "    r'\\s*([^;<>]+)? ?(?:; )?',\n",
        ")\n",
        "\n",
        "\n",
        "def _get_params(checkpoint):\n",
        "\n",
        "  def transp(kernel):\n",
        "    return np.transpose(kernel, (2, 3, 1, 0))\n",
        "\n",
        "  def conv(name):\n",
        "    return {\n",
        "        'bias': checkpoint[name + '.bias'],\n",
        "        'kernel': transp(checkpoint[name + '.weight']),\n",
        "    }\n",
        "\n",
        "  def resblock(name):\n",
        "    return {\n",
        "        'Conv_0': conv(name + '.0'),\n",
        "        'Conv_1': conv(name + '.2'),\n",
        "        'Conv_2': conv(name + '.4'),\n",
        "    }\n",
        "\n",
        "  return {\n",
        "      '_embeddings': checkpoint['_vq_vae._embedding'],\n",
        "      'Conv_0': conv('decoder.0'),\n",
        "      'ResBlock_0': resblock('decoder.2.net'),\n",
        "      'ResBlock_1': resblock('decoder.3.net'),\n",
        "      'ConvTranspose_0': conv('decoder.4'),\n",
        "      'ConvTranspose_1': conv('decoder.6'),\n",
        "      'ConvTranspose_2': conv('decoder.8'),\n",
        "      'ConvTranspose_3': conv('decoder.10'),\n",
        "      'Conv_1': conv('decoder.12'),\n",
        "  }\n",
        "\n",
        "\n",
        "def _quantized_values_from_codebook_indices(codebook_indices, embeddings):\n",
        "  batch_size, num_tokens = codebook_indices.shape\n",
        "  assert num_tokens == 16, codebook_indices.shape\n",
        "  unused_num_embeddings, embedding_dim = embeddings.shape\n",
        "\n",
        "  encodings = jnp.take(embeddings, codebook_indices.reshape((-1)), axis=0)\n",
        "  encodings = encodings.reshape((batch_size, 4, 4, embedding_dim))\n",
        "  return encodings\n",
        "\n",
        "\n",
        "@functools.cache\n",
        "def _get_reconstruct_masks():\n",
        "  \"\"\"Reconstructs masks from codebook indices.\n",
        "  Returns:\n",
        "    A function that expects indices shaped `[B, 16]` of dtype int32, each\n",
        "    ranging from 0 to 127 (inclusive), and that returns a decoded masks sized\n",
        "    `[B, 64, 64, 1]`, of dtype float32, in range [-1, 1].\n",
        "  \"\"\"\n",
        "\n",
        "  class ResBlock(nn.Module):\n",
        "    features: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "      original_x = x\n",
        "      x = nn.Conv(features=self.features, kernel_size=(3, 3), padding=1)(x)\n",
        "      x = nn.relu(x)\n",
        "      x = nn.Conv(features=self.features, kernel_size=(3, 3), padding=1)(x)\n",
        "      x = nn.relu(x)\n",
        "      x = nn.Conv(features=self.features, kernel_size=(1, 1), padding=0)(x)\n",
        "      return x + original_x\n",
        "\n",
        "  class Decoder(nn.Module):\n",
        "    \"\"\"Upscales quantized vectors to mask.\"\"\"\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "      num_res_blocks = 2\n",
        "      dim = 128\n",
        "      num_upsample_layers = 4\n",
        "\n",
        "      x = nn.Conv(features=dim, kernel_size=(1, 1), padding=0)(x)\n",
        "      x = nn.relu(x)\n",
        "\n",
        "      for _ in range(num_res_blocks):\n",
        "        x = ResBlock(features=dim)(x)\n",
        "\n",
        "      for _ in range(num_upsample_layers):\n",
        "        x = nn.ConvTranspose(\n",
        "            features=dim,\n",
        "            kernel_size=(4, 4),\n",
        "            strides=(2, 2),\n",
        "            padding=2,\n",
        "            transpose_kernel=True,\n",
        "        )(x)\n",
        "        x = nn.relu(x)\n",
        "        dim //= 2\n",
        "\n",
        "      x = nn.Conv(features=1, kernel_size=(1, 1), padding=0)(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "  def reconstruct_masks(codebook_indices):\n",
        "    quantized = _quantized_values_from_codebook_indices(\n",
        "        codebook_indices, params['_embeddings']\n",
        "    )\n",
        "    return Decoder().apply({'params': params}, quantized)\n",
        "\n",
        "  with open(_MODEL_PATH, 'rb') as f:\n",
        "    params = _get_params(dict(np.load(f)))\n",
        "\n",
        "  return jax.jit(reconstruct_masks, backend='cpu')\n",
        "\n",
        "def extract_objs(text, width, height, unique_labels=False):\n",
        "  \"\"\"Returns objs for a string with \"<loc>\" and \"<seg>\" tokens.\"\"\"\n",
        "  objs = []\n",
        "  seen = set()\n",
        "  while text:\n",
        "    m = _SEGMENT_DETECT_RE.match(text)\n",
        "    if not m:\n",
        "      break\n",
        "    gs = list(m.groups())\n",
        "    before = gs.pop(0)\n",
        "    name = gs.pop()\n",
        "    y1, x1, y2, x2 = [int(x) / 1024 for x in gs[:4]]\n",
        "\n",
        "    y1, x1, y2, x2 = map(round, (y1*height, x1*width, y2*height, x2*width))\n",
        "    seg_indices = gs[4:20]\n",
        "    if seg_indices[0] is None:\n",
        "      mask = None\n",
        "    else:\n",
        "      seg_indices = np.array([int(x) for x in seg_indices], dtype=np.int32)\n",
        "      m64, = _get_reconstruct_masks()(seg_indices[None])[..., 0]\n",
        "      m64 = np.clip(np.array(m64) * 0.5 + 0.5, 0, 1)\n",
        "      m64 = PIL.Image.fromarray((m64 * 255).astype('uint8'))\n",
        "      mask = np.zeros([height, width])\n",
        "      if y2 > y1 and x2 > x1:\n",
        "        mask[y1:y2, x1:x2] = np.array(m64.resize([x2 - x1, y2 - y1])) / 255.0\n",
        "\n",
        "    content = m.group()\n",
        "    if before:\n",
        "      objs.append(dict(content=before))\n",
        "      content = content[len(before):]\n",
        "    while unique_labels and name in seen:\n",
        "      name = (name or '') + \"'\"\n",
        "    seen.add(name)\n",
        "    objs.append(dict(\n",
        "        content=content, xyxy=(x1, y1, x2, y2), mask=mask, name=name))\n",
        "    text = text[len(before) + len(content):]\n",
        "\n",
        "  if text:\n",
        "    objs.append(dict(content=text))\n",
        "\n",
        "  return objs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-sYkgcOECoP"
      },
      "outputs": [],
      "source": [
        "result = result[len(input_text):].lstrip(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqLZXDQOBsk6"
      },
      "outputs": [],
      "source": [
        "width = input_image.size[0]\n",
        "height = input_image.size[1]\n",
        "masks = extract_objs(result, width, height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spGD-3_cBy3P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(input_image, cmap='gray')\n",
        "\n",
        "for _ in masks:\n",
        "    plt.imshow(_['mask'], cmap='viridis', alpha=0.4, vmin=0, vmax=1)\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}